---
title: "Proyecto Final Econometría en R"
output: html_notebook
---
## Cargando las librerías a utlizar

```{r}
library(xgboost)
library(dplyr)
library(fastDummies)
library(caret)
library(doParallel)
library(tune)
library(parsnip)
library(recipes)
library(dials)
library(rsample)
library(yardstick)
library(workflows)
library(tibble)
library(DescTools)
library(ggplot2)
library(skimr)
library(DataExplorer)
```

## Cargando los archivos de datos

```{r}
# Establecer una semilla global para reproducibilidad
set.seed(123)

# Cargar los datos
train <- read.csv("train.csv")
# Cargar el archivo de prueba
test <- read.csv("test.csv")
```

## Exploración de datos (EDA)

```{r}
# Ver el tamaño de los datasets
cat("Tamaño del dataset de entrenamiento:", dim(train), "\n")
cat("Tamaño del dataset de prueba:", dim(test), "\n")

# Mostrar las primeras filas de los datasets
head(train)
head(test)
```
## Resumen estadístico de los datos

```{r}
# Resumen estadístico de los datasets
summary(train)
summary(test)
```

## Distribuciones de las variables

```{r}
plot_histogram(train)
plot_histogram(test)
```

## Análisis de las variables categóricas

```{r}
# Barras de las variables categóricas
plot_bar(train)
plot_bar(test)
```

## Comprobar duplicados

```{r}
# Comprobar duplicados
cat("Filas duplicadas en el dataset de entrenamiento:", sum(duplicated(train)), "\n")
cat("Filas duplicadas en el dataset de prueba:", sum(duplicated(test)), "\n")
```

## Correlación entre variables

```{r}
# Matriz de correlación
correlation_matrix <- cor(train %>% select_if(is.numeric), use = "complete.obs")
print(correlation_matrix)

# Heatmap de la matriz de correlación
library(corrplot)
corrplot(correlation_matrix, method = "circle")
```

## Exploración visual de variables

```{r}
# Relaciones entre variables numéricas
ggplot(train, aes(x = median_income, y = median_house_value)) +
  geom_point(alpha = 0.5) +
  theme_minimal() +
  labs(title = "Relación entre median_income y median_house_value",
       x = "Median Income",
       y = "Median House Value")

# Distribución de median_house_value por ocean_proximity
ggplot(train, aes(x = ocean_proximity, y = median_house_value)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de median_house_value por ocean_proximity",
       x = "Ocean Proximity",
       y = "Median House Value")
```
## Creación de nuevas características

```{r}
# Crear nuevas características derivadas
train <- train %>%
  mutate(
    rooms_per_household = total_rooms / households,
    bedrooms_per_household = total_bedrooms / households,
    bedrooms_per_room = total_bedrooms / total_rooms,
    population_per_household = population / households,
    log_median_income = log(median_income + 1),
    interaction_income_rooms = median_income * total_rooms,
    interaction_income_bedrooms = median_income * total_bedrooms,
    population_density = population / total_rooms,
    income_per_room = median_income / total_rooms,
    income_per_bedroom = median_income / total_bedrooms,
    log_total_rooms = log(total_rooms + 1),
    log_total_bedrooms = log(total_bedrooms + 1),
    age_income_ratio = housing_median_age / median_income,
    log_population_density = log(population / total_rooms + 1)
  )

test <- test %>%
  mutate(
    rooms_per_household = total_rooms / households,
    bedrooms_per_household = total_bedrooms / households,
    bedrooms_per_room = total_bedrooms / total_rooms,
    population_per_household = population / households,
    log_median_income = log(median_income + 1),
    log_median_income = median_income * total_rooms,
    interaction_income_bedrooms = median_income * total_bedrooms,
    population_density = population / total_rooms,
    income_per_room = median_income / total_rooms,
    income_per_bedroom = median_income / total_bedrooms,
    log_total_rooms = log(total_rooms + 1),
    log_total_bedrooms = log(total_bedrooms + 1),
    age_income_ratio = housing_median_age / median_income,
    log_population_density = log(population / total_rooms + 1)
  )
```

## Exploración de Variables Derivadas

```{r}
# Visualizar las nuevas características derivadas
summary(train %>% select(rooms_per_household, bedrooms_per_household, bedrooms_per_room, population_per_household, log_median_income, log_median_income, interaction_income_bedrooms, population_density, income_per_room, income_per_bedroom, log_total_rooms, log_total_bedrooms, age_income_ratio, log_population_density))
```

## Usar skimr para un Resumen Completo

```{r}
# Resumen completo con skimr
skim(train)
skim(test)
```
## Imputar valores faltantes

```{r}
# Imputar valores faltantes en el conjunto de entrenamiento con la media de la columna correspondiente
train_imputed <- train %>%
  mutate(across(everything(), ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))

# Imputar valores faltantes con la media de la columna correspondiente
test_imputed <- test %>%
    mutate(across(everything(), ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))
```

## Transformación logarítmica de variables

```{r}
# Transformación Logarítmica
train_log_transformed <- train_imputed %>%
  mutate(across(c("total_rooms", "total_bedrooms", "population", "households"), log1p))

test_log_transformed <- test_imputed %>%
    mutate(across(c("total_rooms", "total_bedrooms", "population", "households"), log1p))
```

## Escalado de características

```{r}
numeric_cols <- names(train)[sapply(train, is.numeric)]
numeric_cols <- setdiff(numeric_cols, "median_house_value")

# Escalado Robusto
preProc <- preProcess(train_log_transformed[, numeric_cols], method = c("range"))

train_scaled <- train_log_transformed
train_scaled[, numeric_cols] <- predict(preProc, train_log_transformed[, numeric_cols])

test_scaled <- test_log_transformed
test_scaled[, numeric_cols] <- predict(preProc, test_log_transformed[, numeric_cols])
```

## Transformar variable categórica "ocean_proximity"

```{r}
# Transformar la variable categórica 'ocean_proximity' en variables dummy
train_with_dummies <- train_scaled %>%
  mutate(across(ocean_proximity, as.factor)) %>%
  dummy_cols(select_columns = "ocean_proximity", remove_first_dummy = TRUE, remove_selected_columns = TRUE)

test_with_dummies <- test_scaled %>%
  mutate(across(ocean_proximity, as.factor)) %>%
  dummy_cols(select_columns = "ocean_proximity", remove_first_dummy = TRUE, remove_selected_columns = TRUE)
```

## Entrenar inicialmente el modelo con todas las características

```{r}
# Convertir train y test a matrices
train_matrix <- as.matrix(train_with_dummies)
test_matrix <- as.matrix(test_with_dummies)

# Crear los conjuntos de datos para XGBoost
dtrain <- xgb.DMatrix(data = train_matrix[, -which(colnames(train_matrix) == "median_house_value")],
                      label = train_matrix[, "median_house_value"])

dtest <- xgb.DMatrix(data = test_matrix)

# Definir lista de parámetros
params <- list(
  objective = "reg:squarederror",
  eta = 0.03,  #0.03 Reducing the learning rate
  max_depth = 7, #7
  subsample = 0.85, #0.9
  colsample_bytree = 0.56, #0.8
  lambda = 2,  # 2 L2 regularization
  alpha = 0.5,  # 0.5 L1 regularization
  gamma = 0,  # Controla la reducción mínima en la función de pérdida necesaria para dividir
  max_delta_step = 0.0,  # Controla el tamaño máximo de los pasos de cada iteración
  nthread = 1  # Utilizar un solo hilo para asegurar reproducibilidad
)

xgb_model <- xgb.train(params, dtrain, nrounds = 100, watchlist = list(train = dtrain), print_every_n = 10)

```
## Evaluar importancia de las características

```{r}
# Evaluar importancia de características con nuevas características
importance_new <- xgb.importance(model = xgb_model)
xgb.plot.importance(importance_new)
```

## Seleccionar las mejores características

```{r}
# Seleccionar las mejores características
selected_features <- c("id","longitude", "latitude", "housing_median_age", "total_rooms", "total_bedrooms", "population", "households", "median_income", "rooms_per_household", "bedrooms_per_household", "bedrooms_per_room", "population_per_household", "log_median_income", "interaction_income_rooms", "interaction_income_bedrooms", "population_density", "income_per_room", "income_per_bedroom", "age_income_ratio", "log_population_density", "ocean_proximity_INLAND",   "ocean_proximity_NEAR OCEAN" )

train_selected <- train_with_dummies %>%
  select(all_of(selected_features), median_house_value)

test_selected <- test_with_dummies %>%
  select(all_of(selected_features))
```

## Re-entrenar el modelo con las características seleccionadas

```{r}
# Convertir a matrices train_selected y test_selected
train_matrix <- as.matrix(train_selected)
test_matrix <- as.matrix(test_selected)

# Crear los conjuntos de datos para XGBoost
dtrain <- xgb.DMatrix(data = train_matrix[, -which(colnames(train_matrix) == "median_house_value")],
                      label = train_matrix[, "median_house_value"])

dtest <- xgb.DMatrix(data = test_matrix)

params <- list(
  objective = "reg:squarederror",
  eta = 0.03,  #0.03 Reducing the learning rate
  max_depth = 7, #7
  subsample = 0.85, #0.9
  colsample_bytree = 0.56, #0.8
  lambda = 2,  # 2 L2 regularization
  alpha = 0.5,  # 0.5 L1 regularization
  gamma = 0,  # Controla la reducción mínima en la función de pérdida necesaria para dividir
  max_delta_step = 0.0,  # Controla el tamaño máximo de los pasos de cada iteración
  nthread = 1  # Utilizar un solo hilo para asegurar reproducibilidad
)

```

## Validación cruzada

```{r}
set.seed(123)
cv <- xgb.cv(params, dtrain, nrounds = 5000, nfold = 10, metrics = "rmse", early_stopping_rounds = 100)
```

## Obtener el mejor número de nrounds

```{r}
# Obtener el mejor número de rounds
best_nrounds <- cv$best_iteration
cat("Best number of rounds:", best_nrounds, "\n")
```

## Entrenar el modelo final con el mejor número de rounds

```{r}
# Entrenar el modelo final con el mejor número de rounds
set.seed(123)
xgb_model <- xgb.train(params, dtrain, nrounds = best_nrounds)
```

## Obtener predicciones

```{r}
test_predictions <- predict(xgb_model, dtest)
head(test_predictions)
```

## Crear dataframe y archivo de submission

```{r}
# Crear un dataframe para las predicciones en el formato requerido
submission <- data.frame(id = test$id, median_house_value = test_predictions)

# Verificar si hay valores NA en el dataframe de submission
na_submission <- sum(is.na(submission))
cat("Valores NA en el dataframe de submission:", na_submission, "\n")

# Guardar el dataframe en un archivo CSV
if (na_submission == 0) {
  write.csv(submission, "submission_r.csv", row.names = FALSE)
} else {
  stop("El archivo de submission contiene valores NA.")
}

head(submission)
```

